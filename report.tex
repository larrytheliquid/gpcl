\title{\textbf{Final Report}\\Higher-Order Genetic Programming \\for Semantic Unifiers}

\author{Larry Diehl}
\date{\today}

\documentclass{article}

\usepackage{listings}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage[hscale=0.7,vscale=0.8]{geometry}

\newcommand{\n}[1]{\textrm{#1}}

\begin{document}
\lstset{language=Haskell}

\maketitle

\section{Project Description}

My project is about solving for existential variables in one or more
equations, such that the equations become satisfied after semantic
reductions have occurred. This ends up being a restricted form of a
semantic unification problem that has several universally quantified
variables and a single existential variable. The left hand-side of the
equation is always the existential variable applied to some number of
arbitrary expressions, and the right-hand side is an arbitrary
expression. A futher restriction is that the aforementioned arbitrary
expressions cannot include the existential variable.

Notably, the a solution for an existential variable can be a
higher-order term -- a function that takes other functions as
arguments. I use genetic programming, mostly replicating the work by
Matthias Fuchs in his ``Evolving Combinators'' paper, to solve for the
existential variables. The interesting part of this kind of GP is that
higher-order solutions can be evolved. In standard GP with lambda
terms, a crossover could result in variables unintentionally capturing
other variables, or referencing variables not currently in scope. In
Fuchs' GP, the population of candidate solutions are higher-order
combinators. Trees of applications of combinators implicitly
manipulate variables (via point-free programming), but crossover is
not problematic because variables are never explicitly bound or
referenced.

\subsection{Combinatory Logic Problems}

Most of my time was spent using the project to solve combinatory logic
problems. For example, the following combinatory logic problem asks for a term
consisting exclusively of combinators that is equivalent to the
desired lambda-expression.

$$
T = \lambda a,b . ~ b ~ a
$$

A solution to this problem is the combinator below.

$$
(S(K(S((SK)K))))K
$$

In my system, this problem is represented by the following equation.

$$
\forall a,b . ~ \exists T . ~ T ~ a ~ b = b ~ a
$$

Besides functions, I was also interested in evolving problems
containing datatypes. Notably, problems with datatypes can be
considered a subset of combinatory logic problems by using church
encodings. For example, below if the church-encoding of true and
false.

\begin{align*}
\n{true} &= \lambda a. \lambda b. a\\
\n{false} &= \lambda a. \lambda b. b
\end{align*}

Using Church-encodings, you can represent the ``and'' problem as
follows.

$$
\forall a,b . ~ \exists \n{and} . ~ \n{and} ~ a ~ b = a ~ b ~ a
$$

My algorithm has to give solutions in terms of some primitive set of
combinators. I started with just S and K, which are sound and complete
for the implicational fragment of intuitionistic logic. However, after
experimentation I ended up discovering that S, K, I, B, and C are a
good base set. The combinators B and C can be seen as common/useful
specializations of S, and are due to the logician Moses Sch{\"o}nfinkel.

\begin{align*}
S &= \lambda a,b,c . ~ a ~ c ~ (b ~ c)\\
K &= \lambda a,b . ~ a\\
I &= \lambda a . ~ a\\
B &= \lambda a,b,c . ~ a ~ (b ~ c)\\
C &= \lambda a,b,c . ~ a ~ c ~ b
\end{align*}

The GP system is based on term-rewriting, so the axioms above are
actually encoded as follows.

\begin{align*}
S ~ a ~ b ~ c &= a ~ c ~ (b ~ c)\\
K ~ a ~ b &= a\\
I ~ a &= a\\
B ~ a ~ b ~ c &= a ~ (b ~ c)\\
C ~ a ~ b ~ c &= a ~ c ~ b
\end{align*}


\subsection{Hilbert System Problems}

Besides Church-encoded problems, I also wanted to solve problems with
native datatypes (to avoid the inneficiencies associated with
encodings, and to be more similar to real languages).
To do so, I ended up using a Hilbert system. A Hilbert system replaces
the standard implication introduction and elimination rules with the
combinators S and K, and axiomatically extends the system with other
native types. For example, below is the Hilbert system for a language
with booleans.

\begin{align*}
S ~ a ~ b ~ c &= a ~ c ~ (b ~ c)\\
K ~ a ~ b &= a\\
\n{If} ~ \n{true} ~ a ~ b &= a\\
\n{If} ~ \n{false} ~ a ~ b &= b
\end{align*}

Now, my system can encode the ``and'' problem using native datatypes of a
Hilbert system as follows.

\begin{align*}
\forall a,b . ~ \exists \n{and} .\\
\n{and} ~ \n{true} ~ \n{true} &= \n{true}\\
&\land\\
\n{and} ~ \n{false} ~ b &= \n{false}\\
&\land\\
\n{and} ~ a ~ \n{false} &= \n{false}
\end{align*}

The problem above demonstrates two extensions of my system, where we
can give multiple fitness cases (multiple equations), and we can apply
arbitrary expressions (e.g. ``true'' instead of just variables) to the
desired existential on the left-hand side.

\subsection{Genetic Programming Algorithm}

The GP algorithm is a mostly-standard GP implementation. The novelty
(thanks to Kuchs) lies in the \textit{representation} of candidate
solutions, and the \textit{fitness function}. Recall that the RHS of
equations in problems can mention the universally quantified
variables, but the LHS cannot. This restrictions allows for the
candidate solutions to simply be abstract syntax trees with binary
branches (representing function application) and atoms at the leaves
(representing combinators). Notably, a leaf cannot mention a variable.

To compute fitness, we reduce the RHS and compare it to the result of
reducing the LHS after applying its arguments to the candidate
existential variable solution. However, the comparison is not merely a
binary comparison. Instead, it is a structural difference calculation
of the two resulting abstract syntax trees. Furthermore, there is a
weighting mechanism to assign higher fitness scores to solutions that
do not have some minimum number of combinators at the leaves (this
algorithm input is called the ``minimum structure'').

\subsubsection{My Changes}

Changes that I introduced into the algorithm include a 1-level
tournament selection (pick a parent by comparing the fitness of two
\textit{random} candidates)
This is known to perform better than Kuchs' selection (pick a parent
by selecting a candidate from the population with a bias towards the
fitter-end of the spectrum).
Additionally, Kuchs did not have mutation so I added it as an option
for the user.
I also added a novel option to partially evaluate population
candidates during the algorithm run, thus removing bloat. Finally,
Kuchs performed crossover by first crossing over parents, then
recursively trying again if the maximum depth requirement was
violated. I improved the algorithm by only choosing from crossover
points that result in a child satisfying the maximum depth
requirement. This is accomplished by filtering the depth of all
subnodes of the second parent by whether they are
less-than-or-equal-to the maximum depth minus the distance from the
point of the first parent to the root.

\subsection{Portion of Project Completed}

I implemented all the functionality I set out to for the project, but
I only tested boolean problems in the Hilbert system portion (I also wanted to
test more boolean problems and numeric problems). Additionally, I
evaluated my results by manual inspection of output data, and I wanted
to make some fancy graphs to more easily identify good learning.

\section{Unanticipated Obstacles}

About midway through the course I added partial evaluation to my GP
algorithm. Later I noticed that the algorithm was slow on large
problems, and turning on mutation would sometimes cause infinite
loops. The solution to this mystery was that partial normalization can
sometimes \textit{increase} the solution size, making it bigger than
the maximum depth requirement. Once that invariant was violated, other
parts of the algorithm that depended on it could loop. I got rid of
this problem by only using the partial evaluation result if its depth
was smaller than the original candidate.

\section{Lessons Learned}

\begin{itemize}
\item Always test with a random or brute force algorithm first. This can
help you find which problems are difficult in the first place, so you
can focus on making your algorithm to better on those.
\item Use dynamic checks of invariants in your algorithm in case future
changes break them.
\end{itemize}

\section{Code Statistics}

\section*{Appendix}
\appendix

\section{Evo.hs}

\begin{lstlisting}
{-# LANGUAGE
    ViewPatterns
  , OverloadedStrings
  , ConstraintKinds
  #-}

module Evo where
import Tree
import Exp
import Control.Applicative
import Control.Monad.Reader
import Control.Monad.State
import System.Random
import Data.List
import Data.Bifunctor

----------------------------------------------------------------------

data Options a = Options
  { category :: String
  , name :: String
  , maxInitDepth :: Int
  , maxGeneticDepth :: Int
  , popSize :: Int
  , maxGen :: Int
  , elitism :: Float
  , mutationRate :: Float
  , minStruture :: Int
  , attempts :: Int
  , seed :: Int
  , cases :: Cases a
  , randStrat :: Bool
  , normalize :: Bool
  }

----------------------------------------------------------------------

type Evo a = ReaderT (Options a) (State StdGen)
type Gen = Int
type Indiv a = (Tree a , Int)
type Population a = [Indiv a]

randInt :: Int -> Evo a Int
randInt n = state $ randomR (0, pred n)

randFloat :: Evo a Float
randFloat = state random

randBool :: Evo a Bool
randBool = (0 ==) <$> randInt 2

randElem :: [b] -> Evo a b
randElem xs = (xs !!) <$> randInt (length xs)

randZip :: Tree a -> Evo a (Zipper a)
randZip t = locate t <$> randInt (size t)

randBoundedZip :: Int -> Tree a -> Evo a (Zipper a)
randBoundedZip bound t = (zs !!) <$> randInt (length zs)
  where zs = filter ((<= bound) . depth . fst) (traverse (root t))

mkIndiv :: Scorable a => Tree a -> Evo a (Indiv a)
mkIndiv t = do
  minStruture <- asks minStruture
  cases <- asks cases
  normalize <- asks normalize
  return (score normalize minStruture t cases)

----------------------------------------------------------------------

mutate :: Enumerable a => Tree a -> Evo a (Tree a)
mutate t1 = do
  maxGeneticDepth <- asks maxGeneticDepth
  z <- randZip t1
  t2 <- randTree' (maxGeneticDepth - currentDepth z)
  return $ rootTree (replace t2 z)

crossover :: Tree a -> Tree a -> Evo a (Tree a)
crossover t1 t2 = do
  maxGeneticDepth <- asks maxGeneticDepth
  z1 <- randZip t1
  z2 <- randBoundedZip (maxGeneticDepth - currentDepth z1) t2
  return $ rootTree (replace (currentTree z2) z1)

randTree' :: Enumerable a => Int -> Evo a (Tree a)
randTree' n = do
  b <- randBool
  if b || n <= 0
  then Leaf <$> randElem enum
  else Branch <$> randTree' (pred n) <*> randTree' (pred n)

randTree :: Enumerable a => Evo a (Tree a)
randTree = randTree' =<< asks maxInitDepth

----------------------------------------------------------------------

type Randomizable a = (Enum a, Bounded a, Eq a, Contractible a)

randIndiv :: Randomizable a => Evo a (Indiv a)
randIndiv = do
  t <- randTree
  mkIndiv t

mutationByFitness :: Int -> Evo a Float
mutationByFitness 0 = return 0.0
mutationByFitness _ = asks mutationRate

mutateIndiv :: Randomizable a => Indiv a -> Evo a (Indiv a)
mutateIndiv x@(t , i) = do
  n  <- randFloat
  n' <- mutationByFitness i
  if n < n'
  then mkIndiv =<< mutate t
  else return x

randIndivs :: Randomizable a => Int -> Evo a (Population a)
randIndivs n | n <= 0 = return []
randIndivs n | otherwise = insertIndiv <$> randIndiv <*> randIndivs (pred n)

initial :: Randomizable a => Evo a (Population a)
initial = randIndivs =<< asks popSize

select :: Randomizable a => Population a -> Evo a (Indiv a)
select ts = do
  t1 <- randElem ts
  t2 <- randElem ts
  return $ if snd t1 <= snd t2 then t1 else t2

breed :: Randomizable a => Population a -> Evo a (Indiv a)
breed ts = do
  t1 <- fst <$> select ts
  t2 <- fst <$> select ts
  t' <- crossover t1 t2
  mkIndiv t'

insertIndiv :: Indiv a -> Population a -> Population a
insertIndiv t ts = insertBy (\x y -> compare (snd x) (snd y)) t ts

tooLarge :: Indiv a -> Evo a Bool
tooLarge t = (depth (fst t) >) <$> asks maxGeneticDepth

isSolution :: Indiv a -> Bool
isSolution t = snd t == 0

mutateGen :: Randomizable a => Population a -> Evo a (Population a)
mutateGen = foldM (\xs x -> flip insertIndiv xs <$> mutateIndiv x) []

crossoverGen :: Randomizable a => Population a -> Population a -> Evo a (Population a)
crossoverGen ts ts' | length ts <= length ts' = return ts'
crossoverGen ts ts' | otherwise = do
  t' <- breed ts
  crossoverGen ts (insertIndiv t' ts')

nextGen :: Randomizable a => Population a -> Population a -> Evo a (Population a)
nextGen ts ts' = mutateGen =<< crossoverGen ts ts'

elites :: Population a -> Evo a (Population a)
elites ts = do
  elitism <- asks elitism
  return $ take (truncate (fromIntegral (length ts) * elitism)) ts

evolve :: Randomizable a => Gen -> Population a -> Evo a (Gen , Population a)
evolve n ts = do
  maxGen <- asks maxGen
  randStrat <- asks randStrat
  if n >= maxGen || isSolution (head ts)
  then return (n , ts)
  else evolve (succ n) =<< strategy randStrat
  where strategy randStrat = if randStrat then initial else (nextGen ts =<< elites ts)

evo :: Randomizable a => Evo a (Gen , Population a)
evo = evolve 0 =<< initial

runEvo :: Randomizable a => Options a -> [(Gen , Population a)]
runEvo opts = map (\r -> fst $ runState (runReaderT evo opts') r) rs
  where
  rs = map mkStdGen $ take (attempts opts) $ randoms (mkStdGen (seed opts))
  opts' = opts { cases = map (bimap (map norm) norm) (cases opts) }

----------------------------------------------------------------------

defaultOpts :: Options a
defaultOpts = Options
  { category = ""
  , name = ""
  , maxInitDepth = 10
  , maxGeneticDepth = 17
  , popSize = 1000
  , maxGen = 30
  , elitism = 0.3
  , mutationRate = 0.0
  , minStruture = 15
  , attempts = 10
  , seed = 42
  , cases = []
  , randStrat = False
  , normalize = False
  }

----------------------------------------------------------------------
\end{lstlisting}



\end{document}

