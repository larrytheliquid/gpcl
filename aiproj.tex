\title{Higher-Order Genetic Programming \\for Semantic Unification}
\author{
  Larry Diehl \\
  Department of Computer Science\\
  Portland State University
}
\date{\today}

\documentclass{article}

\usepackage{graphicx}
\usepackage[hscale=0.7,vscale=0.8]{geometry}

\begin{document}

\maketitle

\begin{abstract}
Typical genetic programming (GP) synthesizes programs from a pre-existing
set of first-order operators, usually operations of some abstract
datatype. Our project will use GP to synthesize higher-order programs
(functions which may take other functions as arguments). 

The problems solved by our system will be finding solutions to
variables appearing in equational constraints, i.e. unification
problems. While syntactic unification (where solutions are
first-order terms that do not induce computation) is decidable,
semantic unification (where solutions can induce computation, and can
be lambda-terms) is not, making it a desirable candidate
for the application of GP.
\end{abstract}

\section{Description}
Many logic-based software systems use a unification algorithm to solve
key-problems in their domain. The point of unification is to find a
solution to a variable appearing in an equation, such that the
equation is satisfied.
For example, many Prolog implementations
use unification to solve search problems over relations. The most
common unification algorithms are syntactic. In syntactic unification,
a solution may be a tree-based data structure, but plugging the
solution into an equation does not cause compuation to occur. In
semantic unification, a solution can fill in missing data that cause
operations in the equation to compute. Because of this, many semantic
unification problem domains are undecidable. In particular,
higher-order semantic unification, where solutions can be
lambda-terms, is undecidable. Higher-order unification is used in
dependently typed programming languages as a feature to allow the user
to omit arguments that can be implicitly inferred by the language.
However, because higher-order unification is undecidable, dependently
typed language usually constrain their solutions to some decidable
sub-domain. I wish to explore using GP for higher-order unification,
so one day dependently typed languages may use the techniques to infer
more complex implicit arguments for users.

%% \paragraph{foo}

\section{Design Requirements}

Implementation of a system that can solve semantic higher-order unification
problems using Genetic Programming (GP). Using genetic programming to
solve for higher-order programs poses several technical challenges.
Functions (lambda-terms) need to deal with variable binding and
function application, which means significant complexity in the
encoding of the GP population. Additionally, finding a solution to a
semantic equation seems like a boolean fitness function, which does
not provide a smooth fitness curve that the algorithm can climb. 

\section{Implementation Plan}

The majority of the project will be replicating the work by Matthias
Fuchs in his ``Evolving Combinators'' paper. Instead of directly
evolving lambda-terms, Fuchs evolves logically-equivalent combinators
from combinatory logic. This sidesteps the encoding problems of
lambda-terms, as generating programs as the composition of combinators
is much easier. Additionally, fitness is judged not only by solution
to equations, but by a structural difference score between both sides
of the equation after the candidate solution has been applied, as well
as criteria for preferring larger (non-trivial) solutions.

After implementing the algorithm to solve standard combinatory logic
problems, I would also like to encode Boolean and Natural Number
problems via Church encodings. Then, I would like to compare
higher-order, combinator-based GP to standard (Koza) GP on boolean and
number problems using first-order primitives (I expect the general
algorithm to do worse, but hopefully not significantly worth).

Additionally, I would like to test if Kuchs' algorithm scales to using
mutiple variables in equations and repeated variables in equations.

Finally, I would like to attempt a novel extension of Fuchs' algorithm
to combinatory logic with other primitive datatypes and operations.
This is called ``illative combinatory logic''. In affect, this means
extending GP to move beyond solving problems in the implicational
fragment of intuitionistic logic, to problems of the broader, more
complete, logic.

\subsection{Language and Development Environment}

I will use Haskell to replicate the algorithms in the Fuchs paper,
using Emacs as the development environment. 

\subsection{Borrowed Code}

For plotting and visualization of the GP algorithms, I will use the
Haskell library easyplot, which is a wrapper around gnuplot. Easyplot
is available via Haskell's standard package manager, Cabal
(\texttt{cabal install easyplot}).
If Kuchs' algorithm ends up requiring a proper term rewrite system
rather than a combinator evaluator written in Haskell, I will use the
Maude system.

\section{Plan for Testing}

I will test the algorithm against the dataset used by Fuchs, namely a
dataset of a competing automated theorem proving tool (OTTER).
Additionally, as mentioned I will compare the first-order GP boolean
and number problems to higher-order GP.

\subsection{Anticipated Obstacles}

I plan to implement the combinator evaluator in Haskell, which is
equivalent to a term rewrite system that is confluent. Because Fuchs'
algorithm I am using comes out of term rewriting research, it may need
a confluence checker. If it does, it's probably easier to directly use
a term rewriting system / programming languages such as Maude.

I'm uncertain Fuchs' algorithm scales to using
multiple variables and reused variables, which would be necessary in a
real unification system. I think it should be okay, since fitness is
just calculated by evaluating the substituted candidate term and doing
a structural similarity check of both sides of the reduced equation.

Specifying a function is often done in terms of several rewriting
equations, while Fuchs' algorithm works over a single equation. It is
possible to combine several equations into a single equation via
disjunctions on the right-hand side of the equation. However, I'm
uncertain about how good evolutionary learning will be for disunctions
in the term languages versus an algorithm that works over multiple
equations as primitives.

\section{Dependencies}

\includegraphics[scale=0.22]{dependencies.png}

\section{Timeline in Weeks}

\begin{enumerate}

\item
\begin{itemize}
\item Read and understand details of Fuchs' paper.
\end{itemize}

\item
\begin{itemize}
\item Implement Fuchs' paper (higher-order GP).
\end{itemize}

\item
\begin{itemize}
\item Gather OTTER test data.
\item Graph my implementation on OTTER data.
\item Evaluate my implementation versus the results claimed in the paper.
\item Debug my implementation.
\end{itemize}

\item
\begin{itemize}
\item Implement Koza first-order reference GP for Boolean problems.
\item Create sample boolean GP problems.
\item Graph and compare Koza versus Fuchs (respectively FO and HO) GP.
\end{itemize}

\item
\begin{itemize}
\item Repeat Koza versus Fuchs for natural number problems.
\item Experiment with multiple variables in equations.
\item Experiment with reused variables in equations.
\end{itemize}

\item
\begin{itemize}
\item Learn Illative combinatory logic.
\item Brainstorm adaptations of Fuchs to Illative combinatory logic.
\end{itemize}

\item
\begin{itemize}
\item Implement adaptations of Fuchs to Illative combinatory logic.
\end{itemize}

\end{enumerate}

\end{document}

